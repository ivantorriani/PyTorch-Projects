{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "09ebab01-6a7e-4cb7-b89f-3a1d6cf5cd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Reminder of Indexing Notation - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#list[:] everything in list\n",
    "#list[a:] everything after ind a in list\n",
    "#list[:b] everything until ind b in a list\n",
    "#list[a:b] everything between ind a and ind b in a list\n",
    "#list[a:b:c] from ind a to ind b in a list, with step size of value c\n",
    "\n",
    "#Extending to Tensors - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "#list[a:] everything after row a in tensor\n",
    "#list[a:, b:] everything after row a and column b in tensor\n",
    "#list[None] adds dimension of size 1 similiar to unsqueeze\n",
    "\n",
    "# Construct a Tensor- - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "points = torch.tensor([4.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "points\n",
    "\n",
    "# Contructing a 2D Tensor, Generalize to any Tensor! - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "newPoints = torch.tensor([[4.0, 1.0], [2.0, 3.0], [4.0, 5.0]])\n",
    "newPoints #Notice the structure! The tensor now takes 2 dimensions, when it previously only took 1.Think systems of equations... nice!\n",
    "\n",
    "newPoints.shape #This describes the m*n size of the tensor! Cool!\n",
    "\n",
    "genTen = torch.zeros(3,2) #Now, you can generalize any dimension tensor, and add the places later!! :D\n",
    "\n",
    "\n",
    "\n",
    "# Accessing data inhigher dimensional tensors - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "newPoints[0,1] #Similiar to linear algebra, this is the A_ij entry!!! These connections are amazing!\n",
    "\n",
    "newPoints[0] #Similiar to linear algebra, this is the ith row of the tensor!\n",
    "\n",
    "# Insanely cool tensor manipulation- - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "image = torch.randn(3,5,5) # Color Channels, Heights, Widths\n",
    "batch = torch.randn(2,3,5,5) # 2 bathces, Color Channels, Heights, Witdths\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "\n",
    "grayscale = image.mean(-3) #The third dimension includes the color channels. Finding the mean of that dimension grayscales an image!\n",
    "batch_grayscale = batch.mean(-3) #Same thing as above, but for the images in batches!\n",
    "\n",
    "grayscale.shape #Grayscaling removed the color channels from dimension 3! So, so, AWESOME! ! ! :D\n",
    "\n",
    "\n",
    "#Unsqueezing and Tensor Compatibility - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1) #Unsqueezing tensors lets it be compatible with other tensors for multiplication! SICK!\n",
    "\n",
    "#Now, this is possible! Tensors are now agreeable :D\n",
    "\n",
    "image_weights = ((image * unsqueezed_weights))\n",
    "batch_weights = ((batch * unsqueezed_weights))\n",
    "\n",
    "#So, this makes sense now. #! What's the significance of summing the third dimension?\n",
    "\n",
    "image_gray_with_weights = image_weights.sum(-3)\n",
    "batch_gray_with_weights = batch_weights.sum(-3)\n",
    "\n",
    "# It's just common practice -- taking the sum of the weighted color channels makes the image grayscale.\n",
    "\n",
    "\n",
    "#Einsum, another way!  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "einsum_grayed_image = torch.einsum('...chw,c ->...hw', image, weights)\n",
    "einsum_grayed_batch = torch.einsum('...abc,a -> ...bc', batch, weights) #chw, abc, is completely your choice!\n",
    "\n",
    "#The point is, the operations involved in einsum allow you to take away certain dimensions, for whatever reason!\n",
    "\n",
    "#  Named Tensors - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "named_image = image.refine_names(...,'a', 'b', 'c') # You can only refine names this directly when they don't already exist! \n",
    "\n",
    "test_t = torch.tensor([1,2,3], names = ('a',)) \n",
    "\n",
    "test_t_aligned = test_t.align_as(named_image) #Aligning adds needed dimensions AND appends names from the desired tensor!!!\n",
    "\n",
    "unnamed_test_t = test_t.rename(None) # Named tensors can be unnamed with this function :D!!!!!!\n",
    "\n",
    "\n",
    "#Data Types for tensors- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# 3 ways to change types :D\n",
    "\n",
    "test_points = torch.tensor([[4,3], [2,1]], dtype = torch.double) \n",
    "\n",
    "other_test_points = torch.tensor([4,3,2,1]).double()\n",
    "\n",
    "more_test_points = other_test_points.to(dtype = torch.short)\n",
    "\n",
    "(more_test_points * other_test_points).dtype #Multiplication always take the higher data type\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d342d2-e919-412d-9b82-a3085f207a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
